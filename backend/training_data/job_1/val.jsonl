{"instruction": "\nI would like to do the following:\n[2,4,3,7,9,3]\n[2,6,9,6,5,8]\n[2,8,7,3,8,6]\n[2,0,7,0,8,4]\n\nI.e. in each phase I would like to modularly (10 in this case) sum up all the values from the beginning of the list to the current position, creating a new list: [2, (2+4) `mod` 10, (2+4+3) `mod` 10, (2+4+3+7) `mod` 10...], and I would like to call this multiple times.\nMy code is:\napplyMulti :: Int -> [Int] -> [Int]\napplyMulti 0 dat = dat\napplyMulti n dat = applyMulti (n - 1) $ apply dat\n\napply :: [Int] -> [Int]\napply dat = scanl1 (\\a x -> (a + x) `mod` 10) dat\n\nThat works fine with small of data and small repetition count. But with a list of 500k Ints running 100 times, it eats up the memory and the program is killed. I don't understand, why. Even 500k * 100 should not be huge, but that could even be optimized by the compiler.\nI also tried a non-tail-recursive version:\napplyMulti n dat = apply . applyMulti (n - 1) $ dat\n\nand I even used:\n{-# LANGUAGE BangPatterns, StrictData, Strict #-}\n\nWhat is my mistake and how should I fix this issue?\n", "input": "", "output": "\n\n\n\n\n\n\n\n            2\n        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI can not reproduce. The memory perhaps increases 200 megabytes, and that includes the ghci runtime itself.\nWe can work with a strict version of scanl however to improve memory usage: scanl' :: (b -> a -> b) -> b -> [a] -> [b]  which will force evaluating the list items as scanl enumerates over it:\nimport Data.List(scanl')\n\napply :: [Int] -> [Int]\napply [] = []\napply (d:ds) = scanl' (\\a x -> (a + x) `mod` 10) d ds\n\n\n\n\n\n\n\n\n\nShare\n\n\n\n                        Follow\n                    \n\n\n\n\n\n\n\n\n\n            answered Jul 29, 2023 at 7:50\n\n\n\n\n\n\nwilleM_ Van OnsemwilleM_ Van Onsem\n\n458k3232 gold badges450450 silver badges582582 bronze badges\n\n\n\n\n\n\n\n1\n\n\n\n\n\n\n\n\n\n\nThanks, scanl' worked. I don't really understand why is that difference, because I used strict evaluation, and I understand that scan1 did not, but a single run of the apply function run smoothly even with larger amount of data. Anyways, I have now a solution :)\n\n\u2013\u00a0FERcsI\n\nJul 30, 2023 at 5:46\n\n\n\n\n\n\nAdd a comment\n\u00a0|\u00a0\n\n\n\n\n", "system": ""}
